# -*- coding: utf-8 -*-
"""ToxicComments.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v4gk0VvadyfLKNeX_PJbyafdRdFnSLcZ

Importing Dependencies
"""

#importing numpy for arrays
import numpy as np

#importing pandas for manipulation of the data
import pandas as pd

#importing matplotlib for using plots
from matplotlib import pyplot as plt

#importing seaborn for using plots
import seaborn as sns

#importing re for regular expressions
import re

"""Data Collection and Pre-Processing"""

# from google.colab import drive
#drive.mount('/content/drive')

#importing the datasets
train_df = pd.read_csv('/content/drive/MyDrive/Summer-Project/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/Summer-Project/test.csv')
print(train_df)

train_df.comment_text[15]

#printing 5 random tuples
train_df.sample(5)

#declaring target columns
cols_target = ['obscene','insult','toxic','severe_toxic','identity_hate','threat']

train_df.describe()

#Checking for the unlabeled data    
unlabelled_in_all = train_df[(train_df['toxic']!=1) & (train_df['severe_toxic']!=1) & (train_df['obscene']!=1) & (train_df['threat']!=1) & (train_df['insult']!=1) & (train_df['identity_hate']!=1)]
print('Percentage of unlabeled comments is ', len(unlabelled_in_all)/len(train_df)*100)

# check for any 'null' comment
no_comment = train_df[train_df['comment_text'].isnull()]
len(no_comment)

#print first 5 tuples of dataset
test_df.head()

print(no_comment)

# let's see the total rows in train, test data and the numbers for the various categories
print('Total rows in test is {}'.format(len(test_df)))
print('Total rows in train is {}'.format(len(train_df)))
print(train_df[cols_target].sum())

# Let's look at the character length for the rows in the training data and record these
train_df['char_length'] = train_df['comment_text'].apply(lambda x: len(str(x)))

# look at the histogram plot for text length
sns.set()
train_df['char_length'].hist()
plt.show()

data = train_df[cols_target]

colormap = plt.cm.Blues
plt.figure(figsize=(7,7))
plt.title('Correlation of features & targets',y=1.05,size=14)
sns.heatmap(data.astype(float).corr(),linewidths=0.1,vmax=1.0,square=True,cmap=colormap, linecolor='white',annot=True)

test_df['char_length'] = test_df['comment_text'].apply(lambda x: len(str(x)))

plt.figure()
plt.hist(test_df['char_length'])
plt.show()

# defining the clean text using regex
def clean_text(text):
    text = text.lower()
    text = re.sub(r"what's", "what is ", text)
    text = re.sub(r"\'s", " ", text)
    text = re.sub(r"\'ve", " have ", text)
    text = re.sub(r"can't", "cannot ", text)
    text = re.sub(r"n't", " not ", text)
    text = re.sub(r"i'm", "i am ", text)
    text = re.sub(r"\'re", " are ", text)
    text = re.sub(r"\'d", " would ", text)
    text = re.sub(r"\'ll", " will ", text)
    text = re.sub(r"\'scuse", " excuse ", text)
    text = re.sub('\W', ' ', text)
    text = re.sub('\s+', ' ', text)
    text = text.strip(' ')
    return text

# clean the comment_text in train_df 
train_df['comment_text'] = train_df['comment_text'].map(lambda com : clean_text(com))
train_df.describe()

# clean the comment_text in test_df
test_df['comment_text'] = test_df['comment_text'].map(lambda com : clean_text(com))

train_df = train_df.drop('char_length',axis=1)

X = train_df.comment_text
test_X = test_df.comment_text

print(X.shape, test_X.shape)

# import and intialize TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
vect = TfidfVectorizer(max_features=5000,stop_words='english')
vect

# learn the vocabulary in the training data, then use it to create a document-term matrix
X_dtm = vect.fit_transform(X)
# examine the document-term matrix created from X_train
X_dtm

# transform the test data using the earlier fitted vocabulary, into a document-term matrix
test_X_dtm = vect.transform(test_X)
# examine the document-term matrix from X_test
test_X_dtm

# import and initialize the Logistic Regression model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
logreg = LogisticRegression(C=12.0)

# create submission file
submission_binary = pd.read_csv('/content/drive/MyDrive/Summer-Project/sample_submission.csv')

import warnings
from sklearn.exceptions import ConvergenceWarning

warnings.simplefilter("ignore", category=ConvergenceWarning)

for label in cols_target:
    print('... Processing {}'.format(label))
    y = train_df[label]
    # train the model using X_dtm & y
    logreg.fit(X_dtm, y)
    # compute the training accuracy
    y_pred_X = logreg.predict(X_dtm)
    print('Training accuracy is {}'.format(accuracy_score(y, y_pred_X)))
    # compute the predicted probabilities for X_test_dtm
    test_y_prob = logreg.predict_proba(test_X_dtm)[:,1]
    submission_binary[label] = test_y_prob

submission_binary.head()

# generate submission file
submission_binary.to_csv('submission_binary.csv',index=False)

# create submission file
submission_chains = pd.read_csv('/content/drive/MyDrive/Summer-Project/sample_submission.csv')

# create a function to add features
def add_feature(X, feature_to_add):
    '''
    Returns sparse feature matrix with added feature.
    feature_to_add can also be a list of features.
    '''
    from scipy.sparse import csr_matrix, hstack
    return hstack([X, csr_matrix(feature_to_add).T], 'csr')

for label in cols_target:
    print('... Processing {}'.format(label))
    y = train_df[label]
    # train the model using X_dtm & y
    logreg.fit(X_dtm,y)
    # compute the training accuracy
    y_pred_X = logreg.predict(X_dtm)
    print('Training Accuracy is {}'.format(accuracy_score(y,y_pred_X)))
    # make predictions from test_X
    test_y = logreg.predict(test_X_dtm)
    test_y_prob = logreg.predict_proba(test_X_dtm)[:,1]
    submission_chains[label] = test_y_prob
    # chain current label to X_dtm
    X_dtm = add_feature(X_dtm, y)
    print('Shape of X_dtm is now {}'.format(X_dtm.shape))
    # chain current label predictions to test_X_dtm
    test_X_dtm = add_feature(test_X_dtm, test_y)
    print('Shape of test_X_dtm is now {}'.format(test_X_dtm.shape))

submission_chains.head()

# generate submission file
submission_chains.to_csv('submission_chains.csv', index=False)

# create submission file
submission_combined = pd.read_csv('/content/drive/MyDrive/Summer-Project/submission_combined.csv')

# corr_targets = ['obscene','insult','toxic']
for label in cols_target:
    submission_combined[label] = 0.5*(submission_chains[label]+submission_binary[label])

submission_combined.head()

# generate submission file
submission_combined.to_csv('submission_combined.csv', index=False)

sb = pd.read_csv('/content/drive/MyDrive/Summer-Project/submission_binary.csv')
print(sb)

b_data = sb[cols_target]

#colormap = plt.cm.GnBu
#plt.figure(figsize=(7,7))
#plt.title('Correlation of features & targets',y=1.05,size=14)
#sns.heatmap(b_data.astype(float).corr(),linewidths=0.1,vmax=1.0,square=True,cmap=colormap, linecolor='white',annot=True)

sc = pd.read_csv('/content/drive/MyDrive/Summer-Project/submission_chains.csv')
print(sc)

c_data = sc[cols_target]

#colormap = plt.cm.coolwarm
#plt.figure(figsize=(7,7))
#plt.title('Correlation of features & targets',y=1.05,size=14)
#sns.heatmap(c_data.astype(float).corr(),linewidths=0.1,vmax=1.0,square=True,cmap=colormap, linecolor='white',annot=True)

scb = pd.read_csv('/content/drive/MyDrive/Summer-Project/submission_combined.csv')
print(scb)

cb_data = scb[cols_target]

#colormap = plt.cm.plasma_r
#plt.figure(figsize=(7,7))
#plt.title('Correlation of features & targets',y=1.05,size=14)
#sns.heatmap(cb_data.astype(float).corr(),linewidths=0.1,vmax=1.0,square=True,cmap=colormap, linecolor='white',annot=True)

